{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khajum/python/blob/main/rag/rag-application-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community langchainhub chromadb langchain langchain-openai langchain-google-genai"
      ],
      "metadata": {
        "id": "P7ZPZ9DN2jGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('openai-api-key')"
      ],
      "metadata": {
        "id": "Ou0xJdSj4Z-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(web_path=[\"https://www.educosys.com/course/genai\"])\n",
        "docs = loader.load()\n",
        "print(docs)"
      ],
      "metadata": {
        "id": "8zId0HhD6diq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-text-splitters"
      ],
      "metadata": {
        "id": "L6GCjpFC_gVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "NwAlpOTn88ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(splits[0])\n",
        "print(splits[2])"
      ],
      "metadata": {
        "id": "67SL64So-x2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(splits))"
      ],
      "metadata": {
        "id": "ITcezmxPB5NU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Ensure GEMINI_API_KEY is available from google.colab.userdata\n",
        "# For this to work, you need to make sure `GEMINI_API_KEY` is set in Colab secrets.\n",
        "os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY') # Uncommented this line to set the environment variable\n",
        "\n",
        "# 3) Create embeddings ( Gemini embeddings) + vector store\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\", google_api_key=os.environ.get('GEMINI_API_KEY'))\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "VgCq1XDkDWBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorstore._collection.count())"
      ],
      "metadata": {
        "id": "qtGxC9BGD4gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorstore._collection.get())"
      ],
      "metadata": {
        "id": "6-rVpzADUJFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Collection 1 - \", vectorstore._collection.get(ids=['ddda27d5-2e6b-43d1-a047-8e2e2ab9f5db'], include=[\"embeddings\",\"documents\"]))\n",
        "print(\"\\n Collection 2 - \", vectorstore._collection.get(ids=['0cc7b678-d375-4720-9a12-3a4917d687cd'], include=[\"embeddings\",\"documents\"]))"
      ],
      "metadata": {
        "id": "djHnjiAsWgd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Build a retriever\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "cjHl8S3ZXgfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community import hub\n",
        "# 5) Pull a RAG prompt from LanchainHub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "c2Z8i9KlXoMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "698e2a5a"
      },
      "source": [
        "!pip install --upgrade langchain langchainhub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# 6) Initialize Gemini LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "_6InXDgacZs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compose: (retriever -> format context -> prompt ->llm ->prase)\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def answer_question(question: str):\n",
        "    # Retrive relavant docs\n",
        "    docs = retriever.get_relevant_documents(query=question)\n",
        "    context = format_docs(docs)\n",
        "\n",
        "    # Run Chain\n",
        "    rag_chain = prompt | retriever | format_docs | llm | parser\n",
        "    return rag_chain.invoke(\"context\" : context, \"question\": question)\n"
      ],
      "metadata": {
        "id": "uFczUMDCdoIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Ask something\n",
        "result = answer_question(\"What is GenAI?\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "6joEvWA7etdd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Get_started.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}